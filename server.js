import express from "express";
import axios from "axios";
import dotenv from "dotenv";

dotenv.config();
const app = express();
const PORT = process.env.PORT || 3000;

// Hugging Face API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
const HF_API_KEY = process.env.HF_API_KEY;
console.log("ðŸ”‘ HF_API_KEY:", HF_API_KEY ? "Loaded" : "Missing");

app.use(express.json());
app.use(express.static("public"));

// âœ… í…ŒìŠ¤íŠ¸ìš© ë£¨íŠ¸ íŽ˜ì´ì§€
app.get("/", (req, res) => {
  res.send("ì„œë²„ ìž‘ë™ ì¤‘ âœ…");
});

// âœ… ì±„íŒ… ìš”ì²­ ì²˜ë¦¬
app.post("/api/chat", async (req, res) => {
  try {
    const userMessage = req.body.message;
    if (!userMessage) return res.status(400).json({ error: "ë©”ì‹œì§€ê°€ ë¹„ì—ˆìŒ" });

    console.log("ðŸ“¨ ì‚¬ìš©ìž:", userMessage);

    // Hugging Face ëª¨ë¸ í˜¸ì¶œ
    const response = await axios.post(
      "https://api-inference.huggingface.co/models/reedmayhew/claude-3.7-sonnet-reasoning-gemma3-12B",
      {
        inputs: userMessage,
        parameters: { max_new_tokens: 200, temperature: 0.7 },
      },
      {
        headers: {
          Authorization: `Bearer ${HF_API_KEY}`,
          "Content-Type": "application/json",
        },
      }
    );

    console.log("âœ… HF ì‘ë‹µ:", response.data);

    // Hugging Face ì‘ë‹µ í˜•ì‹ì— ë§žì¶° í…ìŠ¤íŠ¸ ì¶”ì¶œ
    let reply = "ì‘ë‹µ ì—†ìŒ";
    if (Array.isArray(response.data)) {
      reply = response.data[0]?.generated_text || "ì‘ë‹µ ì—†ìŒ";
    } else if (response.data.generated_text) {
      reply = response.data.generated_text;
    }

    res.json({ reply });
  } catch (error) {
    console.error("âŒ ì˜¤ë¥˜ ë°œìƒ:", error.response?.data || error.message);
    res.status(500).json({
      error: "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ ë°œìƒ",
      details: error.response?.data || error.message,
    });
  }
});

app.listen(PORT, () => {
  console.log(`ðŸš€ ì„œë²„ ì‹¤í–‰ ì¤‘: http://localhost:${PORT}`);
});
